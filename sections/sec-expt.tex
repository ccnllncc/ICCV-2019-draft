\section{Experimental Studies}
\label{sec-expt}

In this section, we conduct two sets of experiments to evaluate (1) the performance of our visual processing module, (2) the accuracy of our inference module, and (3) the overall performance of our approach.

\stitle{Experimental Setting}. %We report settings of experimental studies. 

\etitle{DataSet}. We used two datasets: (1) \kw{Soccer} dataset that we annotated; and (2) X dataset from~\cite{}. We extracted images with subjects of golf and tennis (report Statistics about the dataset). We split \kw{Soccer} (resp. X) data into two parts:{\em  I} (one third) and {\em II} (two thirds), and used {\em II} as training data, and {\em I} as testing data. 

\etitle{Queries}. We used two sets of questions: (1) the set of questions given in Table~\ref{table:questions} for \kw{Soccer} dataset; and (2) another set of questions listed in Table~\ref{} for X dataset. 

(We enlarge the training question scale from 7 into 28, so learning correlation between question and answer does not work at this time. For question details, please refer questionset.txt.rtf.)


%==========Table===================
\begin{table}[htbp]
	\renewcommand{\arraystretch}{1}
	\begin{center}
		\small		
		\begin{tabular}{c|*{2}{l}}
			\Xhline{1pt}
			& Time (ms)  & Acc(\%) \\ \Xhline{0.7pt}
			CNN+LSTM  &  141  &  28.14\\
			HieCoAttenVQA  &  237  &  31.92\\
			Learning2Reason  &  297  &  38.00\\
			Ours ($\gamma=0$)  &  N/A  &  65.85\\
			Ours ($\gamma=0.01$)  &  401  &  55.92\\
			Ours ($\gamma=0.50$)  &  591  &  62.29\\
			Ours ($\gamma=0.99$)  &  680  &  64.02\\
			\Xhline{1pt}
		\end{tabular}
		\caption{A set of questions}
		\label{table:questions}
	\end{center}
\end{table}
%==========Table===================


\begin{table}[thb] 
\footnotesize
\begin{tabular}{|l|l|l|}
\hline
Id & Question                                           & Difficulty \\ \hline
%$Q_{nl_1}$  & Who is this image about?                         & Hard       \\ \hline
$Q_{nl_1}$  & Who is holding the soccer?                         & Easy       \\ \hline
$Q_{nl_2}$  & What is the uniform color of the referee?           & Easy       \\ \hline
$Q_{nl_3}$  & Is there any referee in the image?                 & Easy       \\ \hline
$Q_{nl_4}$  & Which team does the goalkeeper belong to?          & Medium       \\ \hline
$Q_{nl_5}$  & Who is the defending team?                         & Medium       \\ \hline
$Q_{nl_6}$  & Which part of the field are the players being now? & Hard       \\ \hline
$Q_{nl_7}$  & How many players are there in the image?           & Hard     \\ \hline

\multirow{2}{*}{$Q_{nl_8}$ }
 & Is this image about corner kick?           &  \multirow{2}{*}{\color{red}??}  \\ 
 & {\color{red}(If not, just list the correct one.)}  & \\ \hline
 
\multirow{2}{*}{$Q_{nl_9}$}  &   Is this image about penalty kick?  &  \multirow{2}{*}{\color{red}??}    \\ 
 & {\color{red}(If not, just list the correct one.)}  &  \\ \hline
 
\multirow{2}{*}{$Q_{nl_{10}}$}  &  Is this image about kick off?  &  \multirow{2}{*}{\color{red}??}    \\ 
 & {\color{red}(If not, just list the correct one.)}  &  \\ \hline
 
\end{tabular} 
\caption{A set of questions} \label{table:questions}
\end{table}




\subsection{Performance of Visual Task Selecting Policy }

To test the validity of reinforcement learning of selecting visual task modules, we test the inference time over accuracy with the state-of-art~\cite{VQA}~\cite{Lu2016Hie} which is shown in Figure~\ref{TimevsAcc}.

\begin{figure}[h]
\begin{center}
\includegraphics[width=0.9\linewidth]{TimevsAcc.png}
\end{center}
\caption{Inference Time and Accuracy}
\label{fig:TimevsAcc}
\end{figure}

Here to test the generalization, we enlarge the training set by more various question with same meaning. For instance, the original question of $Q_{nl5}$ is \textit{"Who is the defending team?"}, we add three more similar question asking \textit{Who is attacking team?}, \textit{"What is the uniform color of the defending team?"} and \textit{"What is the uniform color of the attacking team?"}. Unlike state-of-art methods answering questions in~\cite{peixi2019}, adding generalization and variation in question would not dramatically change the performance, it is because the structure is not fixed, all the visual task selection is query oriented. For~\cite{hu2017learning}, even though the network is not fixed, the answering part is based on neural network, and essentially it also learns the statically correlation, which leads to the weakness in logical reasoning.

\subsection{Effectiveness of Inference} 
\begin{figure}[tb!]
\centering
\includegraphics[width=\columnwidth]{PredictNB.eps}
\vspace{-2ex}
\caption{Inference Graphs}
\vspace{-2ex}
\label{fig:inferGraph}
\end{figure}


In VQA task, we aim to achieve great performance with short responding time. “CPU Time” evaluates the time cost from features extraction to question answering. All the computation work is implemented on CPU.

In terms of system accuracy, we follow the F-measure. Define that $\#true\_value\_inferred$ is the total number of instances whose attribute $A$ is ``$v$'' and is inferred correctly as ``$v$'', $\#true\_value\_instance$ is the number of all the instances with attribute $A$ of value ``$v$'', and $\#inferred\_instances$ indicates the total number of instances whose attribute $A$ is inferred as ``$v$''. The inference accuracy can be defined as below. 
\begin{equation}
Acc(A=``v") = \frac{2 \cdot (recall(A=``v")) \cdot presision (A = ``v")}{recall(A=``v") + presision (A = ``v")}
\end{equation}
where:
\begin{equation*}
\begin{split}
recall(A=``v") & = \frac{\#true\_value\_inferred}{\#true\_value\_instance} \\
precision(A=``v") & = 
\frac{\#true\_value\_inferred}{\#inferred\_instance}
\end{split}
\end{equation*}

We compare our approach to the state-of-the-art systems, i.e. CNN+LSTM[???], HieCoAttenVQA[???], and Learning2Reason[???]. 

%==========Table===================
\begin{table}[htbp]
	\renewcommand{\arraystretch}{1}
	\begin{center}
		\small		
		\begin{tabular}{c|*{2}{r}}
			\Xhline{1pt}
			  & Time (ms)  & Acc(\%) \\ \Xhline{0.7pt}
			CNN+LSTM  &  141  &  28.14\\
			HieCoAttenVQA  &  237  &  31.92\\
			Learning2Reason  &  297  &  38.00\\
			Ours ($\gamma=0$)  &  N/A  &  65.85\\
			Ours ($\gamma=0.01$)  &  401  &  55.92\\
			Ours ($\gamma=0.50$)  &  591  &  62.29\\
			Ours ($\gamma=0.99$)  &  680  &  64.02\\
			\Xhline{1pt}
		\end{tabular}
	\caption{Accuracy comparison per query and average (\%).}
	\label{tab:AccuracyCmp}
	\end{center}
\end{table}
%==========Table===================


%\autoref{tab:AccuracyCmp} lists the time cost and accuracy results among different approaches. It shows that our approach significantly outperforms CNN+LSTM, HieCoAttenVQA, and Learning2Reason in inference accuracy. The accuracy of our approach is 35.88\%, 32.10\% and 26.02\% higher than results of CNN+LSTM, HieCoAttenVQA, and Learning2Reason, respectively. 

\autoref{tab:AccuracyCmp} lists the time cost and accuracy results among different approaches. For CNN+LSTM, HieCoAttenVQA, and Learning2Reason, their systems work quite efficient with responding time less than 300ms. But the accuracies of these three approaches are lower than 40\%, which is unacceptable. Whereas, the system similar to \cite{peixi2019} outperforms all other methods and reaches 65.86\% accuracy, but it costs much more time. Our approach is able to keep balance between effectiveness and efficiency. For effectiveness, our approach achieves 64.02\% accuracy, which is 35.88\%, 32.10\% and 26.02\% higher than results of CNN+LSTM, HieCoAttenVQA, and Learning2Reason, respectively. For efficiency, our approach can reduce the inference time by choosing a small value of $\gamma$.

%Besides, the time cost of our approach is higher than other methods. However, \autoref{tab:AccuracyCmp} indicates that we can reduce the inference time if we choose a small value for $\gamma$.


\stitle{Accuracy of Role}

Based on queries and image characteristics, four variables including $direction$, $status$, $field$, and $unique\_color$ (abbr. $u\_color$) are adopted to calculate conditional probabilities. The inference graph is shown in \autoref{fig:inferGraph}. Note that the domain of variables $direction$, $status$ and $field$ are given in {\color{red}Table ????}, while variable $u\_color$ can have one of two values, to indicate whether a person object has the unique uniform color (=``$U$'') or not (=``$M$'').

%==========Table===================
\begin{table}[htbp]
	\renewcommand{\arraystretch}{1}
	\begin{center}
		\small		
		\begin{tabular}{c|*{3}{r}}
			\Xhline{1pt}
			Role & Precision  & Recall  & Accuracy \\ \Xhline{0.7pt}
			Role = ``G''  &  94.4  &  85.5  &  89.8\\
			Role = ``R''  &  87.4  &  82.8  &  85.0\\
			Role = ``P''  &  98.8  &  99.3  &  99.0\\
			\Xhline{1pt}
		\end{tabular}
	\caption{Inference accuracy of role (\%). Here ``G'', ``R'' and ``P'' indicate goalkeeper, referee and player, respectively.}
	\label{tab:InferAccRole}
	\end{center}
\end{table}
%==========Table===================

Using the conditional probabilities, $VI$ {\color{red}(???)} infers role of each person object. The inference accuracy is shown in \autoref{tab:InferAccRole}. It is easy to find that the inference accuracy for role player reaches 99\%, which is highest among all roles. And the accuracies for different roles are all above 85\%.

\stitle{Accuracy of Team Status}


\stitle{Accuracy of Field Scene}

%===================== figure ============
\begin{figure}[!bth]
	%\scriptsize
	\centering	
	\begin{minipage}[b]{\linewidth}
		\centerline{\includegraphics[width=0.5\linewidth]{example-image-a}}
	\end{minipage}\hfill
	\caption{Attributes of Scene Inference Graph.}
	\label{fig:AtribSceneGraph}
\end{figure}
%===================== figure ============

Field Scene includes four different scenes, \textit{i.e.} corner kick, free kick, penalty kick and kick-off. Practically, corner kick scene always happens as a single player kick the ball within a one-yard radius of the corner flag and most of players gather in the penalty field. Free kick happens outside the penalty area and defensive wall exists mostly. It is much typical for the penalty kick scene because most of players are out of penalty area except kick player and goalkeeper with football in the penalty spot. As for kick-off scene, the ball is played in the center spot with all members of the opposing team at least 10 yards from the ball. Based on these observations, we design an inference graph in \autoref{fig:AtribSceneGraph}.


Inference accuracy is indicated in \autoref{tab:InferAccField} based on inference graph in \autoref{fig:AtribSceneGraph}. As is shown, the inference accuracy of corner kick, free kick, kick-off and penalty kick are 59.57\%, 63.16\%, 85.94\% and 60.00\%, respectively. It is obvious that the scene of kick off reaches the highest accuracy among all.
 

%==========Table===================
\begin{table}[htbp]
	\renewcommand{\arraystretch}{1}
	\begin{center}
		\small		
		\begin{tabular}{c|*{3}{r}}
			\Xhline{1pt}
			Field Type & Precision  & Recall  & F1-score \\ \Xhline{0.7pt}
			Field Scene = ``Co''  &  59.57  &  68.29  &  63.64\\
			Field Scene = ``Fr''  &  63.16  &  58.54  &  60.76\\
			Field Scene = ``Ki''  &  85.94  &  82.09  &  83.97\\
			Field Scene = ``Pe''  &  60.00  &  60.00  &  60.00\\
			\Xhline{0.7pt}
			Average  &  71.28  &  70.73  &  70.89\\
			\Xhline{1pt}
		\end{tabular}
	\caption{Inference accuracy of field scene (\%) with our approach. Here ``Co'', ``Fr'', ``Ki'' and ``Pe'' indicate corner kick, free kick, penalty kick and kick-off, respectively.}
	\label{tab:InferAccField}
	\end{center}
\end{table}
%==========Table===================


In addition, we compared our approach with NuSVC, MLP, and AdaBoost in \autoref{tab:AccFieldCmp}. The results show that the average accuracy of our approach is higher than that of NuSVC and AdaBoost by 4.49\% and 5.97\% respectively, and slightly better than that of MLP.

%==========Table===================
\begin{table}[htbp]
	\renewcommand{\arraystretch}{1}
	\begin{center}
		\small		
		\begin{tabular}{c|*{3}{r}}
			\Xhline{1pt}
			 & Precision  & Recall  & F1-score \\ \Xhline{0.7pt}
			NuSVC  &  68.30  &  65.85  &  66.40\\
			MLP  &  70.80  &  \textbf{70.73}  &  70.32\\
			AdaBoost  &  65.50  &  65.24  &  64.92\\ %\Xhline{0.7pt}
			Ours  &  \textbf{71.28}  &  \textbf{70.73}  &  \textbf{70.89}\\
			\Xhline{1pt}
		\end{tabular}
	\caption{Average accuracy comparison of field scene (\%)}
	\label{tab:AccFieldCmp}
	\end{center}
\end{table}
%==========Table===================



%\stitle{Accuracy of Kick-Off}. {\color{red} SHOW INFERENCE GRAPH AND RESULT TABLE!}
%
%\stitle{Accuracy of Penalty Kick}. {\color{red} SHOW INFERENCE GRAPH AND RESULT TABLE!}
%
%\stitle{Accuracy of Corner Kick}. {\color{red} SHOW INFERENCE GRAPH AND RESULT TABLE!}
%
%\stitle{Accuracy of Attacking Free Kick}. {\color{red} SHOW INFERENCE GRAPH AND RESULT TABLE!}
%
%\stitle{Accuracy of Balls}. {\color{red} Over new dataset. SHOW INFERENCE GRAPH AND RESULT TABLE!}

\subsection{Overall Performance}
\label{sec-overall-performance}
%We use the same question setting as~\cite{peixi2019}, compared the following state-of-the-art methods: \cite{VQA},and~\cite{hu2017learning} with our method ($\gamma$=0.99), the overall performance is shown in Table~\ref{table:stateofart}. 

We compared our proposed method with the following state-of-art methods: LSTM+CNN, HieCoAttenVQA, and Learn2Reason. The results are listed in \autoref{table:stateofart}. The average accuracy using our approach is higher than accuracy of CNN+LSTM, HieCoAttenVQA and Learn2Reason by 20.35\%, 17.64\% and 15.67\%,  respectively. 

%==========Table===================
\begin{table}[htbp]
	\renewcommand{\arraystretch}{1}
	\begin{center}
		\small		
		\begin{tabular}{c|*{4}{c}}
			\Xhline{1pt}
			& CNN+LSTM & HieCoAtten & Learn2Reason & Ours \\ \Xhline{0.7pt}
			$Q_{nl1}$ & 44.23    & 43.62         & 31.12        & \textbf{64.86} \\ 
			$Q_{nl2}$ & 71.31    & \textbf{77.66}         & 9.4          & 63.74 \\ 
			$Q_{nl3}$ & 74.58    & \textbf{83.78}         & 83.21        & 70.00 \\ 
			$Q_{nl4}$ & 40.48    & 39.29         & 51.92        & \textbf{62.14} \\ 
			$Q_{nl5}$ & 49.19    & 49.90         & 30.78        & \textbf{62.58} \\ 
			$Q_{nl6}$ & 20.56    & 18.70         & 30.0         & \textbf{93.33} \\ 
			$Q_{nl7}$ & 11.08    & 12.63         & 36.69        & \textbf{50.60} \\\Xhline{0.7pt} 
			Avg.       & 46.40    & 49.11         & 51.08        & \textbf{66.75} \\
			\Xhline{1pt}
		\end{tabular}
	\caption{Accuracy comparison per query and average (\%)}
	\label{table:stateofart}
	\end{center}
\end{table}
%==========Table===================

